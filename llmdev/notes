- record all answers in JSON format for convenience
for each question,
- ask ollama for topics / subject / general idea of the problem
- record the answer as a hint for next questions
- ask ollama to describe a youtube search query that could find a useful video given the subject matter
to test:
* we want to be able to quantify the performance of ollama
- use a separate model to look at the query, and describe how accurate
it is to the problem, whether or not it might help find a helpful video
- maybe use gpt for the time being, giving a percentage rating of helpfulness
- human / manual checking over each iteration

disadvantages:
- ollama not as well trained and able to pick up on details as gpt
for example, for the same question on modifying string literals in C:
gpt gives "Memory manipulation in C" vs ollama "C string literals"
- ollama does not like to print strictly in a json format, unlike gpt 
when prompted

advantages:
- ollama is a nerd:
    for some reason, instead of providing a search query for the questions,
ollama decided to start solving the questions and explaining the answers

